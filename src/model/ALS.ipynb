{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.12.0 | packaged by conda-forge | (main, Oct  3 2023, 08:43:22) [GCC 12.3.0]\n",
      "Pandas version: 2.1.1\n",
      "PySpark version: 3.4.1\n"
     ]
    }
   ],
   "source": [
    "# set the environment path to find Recommenders\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col \n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import FloatType, IntegerType, LongType\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"PySpark version: {}\".format(pyspark.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging(log_directory, logger_name):\n",
    "    os.makedirs(log_directory, exist_ok=True)\n",
    "\n",
    "    log_filename = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S.log\")\n",
    "    log_filepath = os.path.join(log_directory, log_filename)\n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    handler = logging.FileHandler(log_filepath)\n",
    "    handler.setLevel(logging.INFO)\n",
    "    handler.setFormatter(formatter)\n",
    "\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "def setup_SparkML_logging():\n",
    "    return setup_logging(\"Log/SparkML\", \"ALS_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/10 20:25:14 WARN Utils: Your hostname, sabri-Parallels-Virtual-Platform resolves to a loopback address: 127.0.1.1; using 10.211.55.7 instead (on interface enp0s5)\n",
      "23/12/10 20:25:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/10 20:25:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/12/10 20:25:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"/home/hadoop/Syst-me-de-Recommandation-de-Films-en-Temps-R-el-avec-Apache-Spark-Elasticsearch-Kibana-et-Flask/data/MovieLens\")\n",
    "\n",
    "from MovieLensData import get_all_data\n",
    "\n",
    "try:\n",
    "    # Create a Spark session\n",
    "    spark = SparkSession.builder.appName(\"MovieRecommendation\").getOrCreate()\n",
    "\n",
    "    # Get data from MovieLens\n",
    "    df = get_all_data()\n",
    "\n",
    "    # Select only the desired columns\n",
    "    selected_columns = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "    df = df[selected_columns]\n",
    "\n",
    "    # Convert the final_data DataFrame to a Spark DataFrame\n",
    "    spark_final_data = spark.createDataFrame(df)\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error: {e}\")\n",
    "    # Handle the exception as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|   196|    242|     3|881250949|\n",
      "|   196|    257|     2|881251577|\n",
      "|   196|    111|     4|881251793|\n",
      "|   196|     25|     4|881251955|\n",
      "|   196|    382|     4|881251843|\n",
      "+------+-------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_final_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, test) = spark_final_data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/10 20:25:45 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/12/10 20:25:46 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Define the ALS model\n",
    "import shutil\n",
    "\n",
    "\n",
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "\n",
    "# Define the parameter grid to search for the best hyperparameters\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(als.rank, [10, 20, 30]) \\\n",
    "    .addGrid(als.maxIter, [5, 10, 15]) \\\n",
    "    .addGrid(als.regParam, [0.01, 0.1, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "# Define the evaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "# Create a CrossValidator\n",
    "crossval = CrossValidator(estimator=als,\n",
    "                            estimatorParamMaps=param_grid,\n",
    "                            evaluator=evaluator,\n",
    "                            numFolds=3)  # You can adjust the number of folds\n",
    "# Fit the CrossValidator to the data\n",
    "cv_model = crossval.fit(training)  \n",
    "\n",
    "# Get the best model from cross-validation\n",
    "best_model = cv_model.bestModel\n",
    "\n",
    "model_path = \"/home/hadoop/Syst-me-de-Recommandation-de-Films-en-Temps-R-el-avec-Apache-Spark-Elasticsearch-Kibana-et-Flask/src/model/best_model\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Le répertoire {model_path} existe déjà. Suppression du répertoire existant.\")\n",
    "    shutil.rmtree(model_path)\n",
    "\n",
    "best_model.save(model_path)\n",
    "\n",
    "# Use the best model to make predictions on the test set\n",
    "predictions = best_model.transform(test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9124169376944185\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE\n",
    "evaluator_rmse = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_mae = RegressionEvaluator(metricName=\"mae\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "# Calculate MAE\n",
    "mae = evaluator_mae.evaluate(predictions)\n",
    "print(f\"MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate R2 using RegressionMetrics\n",
    "predictionAndLabels = predictions.select(\"prediction\", \"rating\").rdd.map(lambda x: (float(x[0]), float(x[1])))\n",
    "\n",
    "metrics = RegressionMetrics(predictionAndLabels)\n",
    "r2 = metrics.r2\n",
    "print(f\"R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch.helpers import scan\n",
    "\n",
    "def get_movie_id_by_title(es, index_name, movie_title):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"title\": movie_title\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Use scan to get all documents matching the query\n",
    "    results = scan(es, index=index_name, query=query)\n",
    "\n",
    "    for result in results:\n",
    "        return result[\"_source\"][\"movieId\"]\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_284607/209251494.py:15: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  for result in results:\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "es = Elasticsearch(\"http://localhost:9200\")  # Replace with your Elasticsearch URL\n",
    "\n",
    "movie_inndex = \"movie\"\n",
    "# Get recommendations for a movie title\n",
    "movie_title_to_search = \"Raising Arizona\"\n",
    "\n",
    "\n",
    "print(get_movie_id_by_title(es, movie_inndex, movie_title_to_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_users_ids_for_movie_review(es, index_name, movie_id):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"term\": {\n",
    "                \"movieId\": movie_id\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Use scan to get all documents matching the query\n",
    "    results = scan(es, index=index_name, query=query)\n",
    "\n",
    "    user_ids = set()\n",
    "    for result in results:\n",
    "        user_ids.add(result[\"_source\"][\"userId\"])\n",
    "\n",
    "    return list(user_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['63', '196']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_284607/4101955580.py:14: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  for result in results:\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "es = Elasticsearch(\"http://localhost:9200\")  # Replace with your Elasticsearch URL\n",
    "\n",
    "review_index = \"review\"\n",
    "\n",
    "# Get recommendations for a movie title\n",
    "movie_id = \"762\"\n",
    "\n",
    "\n",
    "print(get_users_ids_for_movie_review(es, review_index, movie_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "def get_recommendations_for_movie(es, als_model, movie_title, num_recommendations=5):\n",
    "    # Step 1: Get movieId for the given movie title\n",
    "    movie_index = \"movie\"\n",
    "    movie_id = get_movie_id_by_title(es, movie_index, movie_title)\n",
    "\n",
    "    if movie_id is None:\n",
    "        print(f\"Movie with title '{movie_title}' not found.\")\n",
    "        return None\n",
    "\n",
    "    review_index = \"review\"\n",
    "    # Step 2: Get user ids that have reviewed the movie\n",
    "    user_ids = get_users_ids_for_movie_review(es, review_index, movie_id)\n",
    "\n",
    "    if not user_ids:\n",
    "        print(f\"No user reviews found for the movie with title '{movie_title}'.\")\n",
    "        return None\n",
    "\n",
    "    # Step 3: Create a DataFrame with user and movie data\n",
    "    user_movie_data = [(int(user_id),) for user_id in user_ids]\n",
    "    schema = StructType([StructField(\"userId\", IntegerType(), True)])\n",
    "    user_movie_df = spark.createDataFrame(user_movie_data, schema)\n",
    "\n",
    "    # Step 4: Use ALS model to get recommendations for the users\n",
    "    recommendations = best_model.recommendForUserSubset(user_movie_df, num_recommendations)\n",
    "\n",
    "    # Extract movie IDs from recommendations DataFrame\n",
    "    movie_ids = [movie.movieId for row in recommendations.rdd.collect() for movie in row.recommendations]\n",
    "\n",
    "\n",
    "    return movie_ids\n",
    "\n",
    "# Example usage:\n",
    "es = Elasticsearch(\"http://localhost:9200\")  # Replace with your Elasticsearch URL\n",
    "\n",
    "# Get recommendations for a movie title\n",
    "movie_title_to_search = \"Toy Story (1995)\"\n",
    "print(get_recommendations_for_movie(es, best_model, movie_title_to_search))\n",
    "\n",
    "\n",
    "es.transport.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Movilens_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
